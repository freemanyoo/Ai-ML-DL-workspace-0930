{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-02T00:54:55.199796Z",
     "start_time": "2025-10-02T00:54:51.230219Z"
    }
   },
   "source": [
    "#파이토치 기본 라이브러리\n",
    "import torch\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# 이미지와 관련된 파이토치 라이브러리\n",
    "import torchvision\n",
    "\n",
    "#이미지 전처리 기능들을 제공하는 라이브러리\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "#데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as p\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T00:54:56.741078Z",
     "start_time": "2025-10-02T00:54:55.205794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# tr.Compose 내에 원하는 전처리를 차례대로 넣어주면 된다.\n",
    "\n",
    "transf = tr.Compose([tr.Resize(16),tr.ToTensor()])\n",
    "# 16x16으로 이미지 크기 변환 후 텐서 타입으로 변환한다.\n",
    "\n",
    "#CIFAR-10이 분류해야 하는 10개의 클래스는 다음과 같습니다.\n",
    "#이미지 크기:\n",
    "# 모든 이미지는 가로 32픽셀, 세로 32픽셀의 매우 작은 컬러(RGB) 이미지\n",
    "# airplane (비행기)\n",
    "# automobile (자동차)\n",
    "# bird (새)\n",
    "# cat (고양이)\n",
    "# deer (사슴)\n",
    "# dog (개)\n",
    "# frog (개구리)\n",
    "# horse (말)\n",
    "# ship (배)\n",
    "# truck (트럭)\n",
    "# torchvision.datasets에서 제공하는 CIFAR10 데이터를 불러온다.\n",
    "# root에는 다운로드 받을 경로를 입력한다.\n",
    "# train=Ture이면 학습 데이터를 불러오고 train=False이면 테스트 데이터를 불러온다.\n",
    "# 미리 선언한 전처리를 사용하기 위해 transform=transf을 입력한다.\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)\n"
   ],
   "id": "5f43de0b78a9b520",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T00:54:57.009283Z",
     "start_time": "2025-10-02T00:54:56.855055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 일반적으로 데이터셋은 이미지와 라벨이 동시에 들어있는 튜플(tuple) 형태다.\n",
    "# (이미지, 라벨)\n",
    "# trainset[0]은 학습 데이터의 첫 번째 데이터로\n",
    "# 이미지 한 장과 라벨 숫자 하나가 저장되어 있다.\n",
    "# 즉, trainset[0][0]은 이미지이며 trainset[0][1]은 라벨이다.\n",
    "\n",
    "print(trainset[0][0].size())\n",
    "\n",
    "# 현재 이미지 사이즈는 3x16x16이다. 여기서 3은 채널 수를 말하고\n",
    "# 16x16은 이미지의 너비와 높이를 의미한다.\n",
    "# 일반적인 컬러 사진은 RGB 이미지이기 때문에 채널이 3개 이고\n",
    "# (너비)x(높이)x(채널 수)로 크기가 표현된다.\n",
    "\n",
    "# 하지만 파이토치에서는 이미지 한 장이 (채널 수)x(너비)x(높이)으로\n",
    "# 표현되니 유의하도록 한다.\n",
    "\n",
    "# DataLoader는 데이터를 미니 배치 형태로 만들어 준다.\n",
    "# 따라서 배치 사이즈 및 셔플 여부 등을 선택할 수 있다.\n",
    "trainloader = DataLoader(trainset, batch_size=50, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=50, shuffle=False)\n",
    "\n",
    "# 즉, batch_size=50, shuffle=True은\n",
    "# 무작위로 데이터를 섞어 한 번 에 50개의 이미지를 묶은 배치로 제공하겠다는 의미다.\n",
    "\n",
    "# len(trainloader)\n",
    "# Output: 1000\n",
    "#\n",
    "# CIFAR10의 학습 이미지는 50000장이고 배치 사이즈가 50장이므로\n",
    "# 1000은 배치의 개수가 된다.\n",
    "\n",
    "# Output: torch.Size([50, 3, 16, 16)\n",
    "#\n",
    "# 배치 이미지를 간단히 확인하기 위해 파이썬에서 제공하는\n",
    "# iter와 next 함수를 이용한다.\n",
    "#\n",
    "# 이를 통 해 trainloader의 첫 번째 배치를 불러올 수 있다.\n",
    "# 1 배치 사이즈는 (배치 크기)×(채널 수)×(너비) (높이)를 의미한다.\n",
    "# 즉, 배치 하나에 이미지 50개가 잘 들어가 있음을 알 수 있다.\n",
    "#\n",
    "\n",
    "# iter, next를 이용해 일부 데이터를 확인할 수 있다.\n",
    "images, labels = next(iter(trainloader))\n",
    "print(\"이미지 사이즈\",images.size())\n",
    "print(\"이미지 라벨즈\",labels)\n",
    "\n",
    "# 일반적으로 학습 데이터는 4차원 형태로 모델에서 사용된다.\n",
    "# (배치 크기)x(채널 수)x(너비)x(높이)\n",
    "# torch.Size([50, 3, 16, 16])\n",
    "oneshot = images[1].permute(1,2,0).numpy()\n",
    "# print(oneshot.size())\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(oneshot)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "id": "32882dc56fa805e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 16])\n",
      "이미지 사이즈 torch.Size([50, 3, 16, 16])\n",
      "이미지 라벨즈 tensor([5, 1, 9, 3, 6, 0, 4, 0, 0, 4, 0, 4, 7, 8, 3, 4, 3, 8, 4, 5, 8, 0, 1, 6,\n",
      "        5, 0, 2, 0, 7, 7, 0, 4, 2, 2, 8, 9, 3, 6, 1, 7, 4, 0, 4, 9, 2, 6, 8, 8,\n",
      "        9, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
